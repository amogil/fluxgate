//! Unified script to validate requirements completeness and consistency.
//!
//! This script performs comprehensive validation:
//! - Completeness: Checks that all expected requirements are present
//! - Consistency: Checks for contradictions and logical conflicts
//! - Cross-references: Validates requirement references
//!
//! Usage: cargo run --bin validate-requirements-quality

use std::collections::{HashMap, HashSet};
use std::fs;
use std::path::Path;

fn main() {
    let requirements_dir = Path::new("docs/development/requirements");

    println!("üîç Validating requirements completeness and consistency...\n");

    // Parse all requirements
    let requirements = parse_requirements(requirements_dir);

    println!("üìã Found {} requirements\n", requirements.len());

    // Check completeness
    let completeness_ok = check_completeness(&requirements);

    // Check consistency
    let consistency_ok = check_consistency(&requirements);

    // Check cross-references
    let crossrefs_ok = check_cross_references(&requirements);

    // Final summary
    println!("\n{}", "=".repeat(60));
    if completeness_ok && consistency_ok && crossrefs_ok {
        println!("‚úÖ ALL VALIDATIONS PASSED");
        println!("   Requirements are complete and consistent");
        std::process::exit(0);
    } else {
        println!("‚ùå VALIDATION FAILED");
        if !completeness_ok {
            println!("   - Completeness issues found");
        }
        if !consistency_ok {
            println!("   - Consistency issues found");
        }
        if !crossrefs_ok {
            println!("   - Cross-reference issues found");
        }
        std::process::exit(1);
    }
}

fn parse_requirements(dir: &Path) -> HashMap<String, Requirement> {
    let mut requirements = HashMap::new();

    for entry in fs::read_dir(dir).unwrap() {
        let entry = entry.unwrap();
        let path = entry.path();
        if path.extension().and_then(|s| s.to_str()) == Some("md") {
            let content = fs::read_to_string(&path).unwrap();
            let file_reqs = extract_requirements(&content, &path);
            for req in file_reqs {
                requirements.insert(req.id.clone(), req);
            }
        }
    }

    requirements
}

#[derive(Debug, Clone)]
struct Requirement {
    id: String,
    #[allow(dead_code)]
    category: String,
    #[allow(dead_code)]
    content: String,
    full_text: String, // Full requirement text including following lines
    #[allow(dead_code)]
    line_number: usize,
    file: String,
}

fn extract_requirements(content: &str, file_path: &Path) -> Vec<Requirement> {
    let mut requirements = Vec::new();
    let file_name = file_path.file_name().unwrap().to_string_lossy().to_string();
    let lines: Vec<&str> = content.lines().collect();

    // Determine category from filename
    let category = if file_name.starts_with("00-") {
        "General"
    } else if file_name.starts_with("01-") {
        "Performance"
    } else if file_name.starts_with("02-") {
        "Functional"
    } else if file_name.starts_with("03-") {
        "Configuration"
    } else if file_name.starts_with("04-") {
        "Testing"
    } else if file_name.starts_with("05-") {
        "CLI"
    } else if file_name.starts_with("06-") {
        "Operational"
    } else if file_name.starts_with("07-") {
        "Observability"
    } else {
        "Unknown"
    };

    for (line_num, line) in lines.iter().enumerate() {
        let chars: Vec<char> = line.chars().collect();
        let mut i = 0;
        while i < chars.len() {
            // Check for single-letter prefixes (G, P, F, C, T, O)
            // Also handle O8. without ** prefix (special case in observability.md)
            if i + 1 < chars.len()
                && matches!(chars[i], 'G' | 'P' | 'F' | 'C' | 'T' | 'O')
                && chars[i + 1].is_ascii_digit()
            {
                let mut num_end = i + 1;
                while num_end < chars.len() && chars[num_end].is_ascii_digit() {
                    num_end += 1;
                }
                // Check if this is a requirement ID (must be followed by . or **)
                // Require . for single-letter prefixes to avoid matching things like "O8 (" in documentation
                let is_requirement_id = num_end < chars.len()
                    && (chars[num_end] == '.'
                        || (num_end + 1 < chars.len()
                            && chars[num_end] == '*'
                            && chars[num_end + 1] == '*'));
                if num_end > i + 1 && is_requirement_id {
                    let req_id: String = chars[i..num_end].iter().collect();
                    // Extract full requirement text (current line + following lines until next requirement or section)
                    #[allow(clippy::needless_borrow)]
                    let (full_text, content_start) =
                        extract_full_requirement_text(&lines, line_num, i);

                    requirements.push(Requirement {
                        id: req_id,
                        category: category.to_string(),
                        content: content_start.trim().to_string(),
                        full_text,
                        line_number: line_num + 1,
                        file: file_name.clone(),
                    });
                    i = num_end;
                    continue;
                }
            }

            // Check for multi-letter prefixes (CLI, UT, FT, OP)
            if i + 3 < chars.len() {
                let prefix3: String = chars[i..i + 3].iter().collect();
                if matches!(prefix3.as_str(), "CLI" | "UT" | "FT" | "OP")
                    && chars[i + 3].is_ascii_digit()
                {
                    let mut num_end = i + 3;
                    while num_end < chars.len() && chars[num_end].is_ascii_digit() {
                        num_end += 1;
                    }
                    if num_end > i + 3 {
                        let req_id: String = chars[i..num_end].iter().collect();
                        #[allow(clippy::needless_borrow)]
                        let (full_text, content_start) =
                            extract_full_requirement_text(&lines, line_num, i);

                        requirements.push(Requirement {
                            id: req_id,
                            category: category.to_string(),
                            content: content_start.trim().to_string(),
                            full_text,
                            line_number: line_num + 1,
                            file: file_name.clone(),
                        });
                        i = num_end;
                        continue;
                    }
                }
            }

            if i + 2 < chars.len() {
                let prefix2: String = chars[i..i + 2].iter().collect();
                if matches!(prefix2.as_str(), "UT" | "FT" | "OP") && chars[i + 2].is_ascii_digit() {
                    let mut num_end = i + 2;
                    while num_end < chars.len() && chars[num_end].is_ascii_digit() {
                        num_end += 1;
                    }
                    if num_end > i + 2 {
                        let req_id: String = chars[i..num_end].iter().collect();
                        #[allow(clippy::needless_borrow)]
                        let (full_text, content_start) =
                            extract_full_requirement_text(&lines, line_num, i);

                        requirements.push(Requirement {
                            id: req_id,
                            category: category.to_string(),
                            content: content_start.trim().to_string(),
                            full_text,
                            line_number: line_num + 1,
                            file: file_name.clone(),
                        });
                        i = num_end;
                        continue;
                    }
                }
            }
            i += 1;
        }
    }

    requirements
}

fn extract_full_requirement_text(
    lines: &[&str],
    start_line: usize,
    start_col: usize,
) -> (String, String) {
    let mut full_text = String::new();
    let mut content_start = String::new();

    // Start from the requirement ID
    let first_line = lines[start_line];
    let chars: Vec<char> = first_line.chars().collect();
    // If requirement starts at beginning of line (start_col == 0 or very small), include entire line
    // Otherwise, start from the requirement ID position
    if start_col < chars.len() {
        let line_rest: String = chars[start_col..].iter().collect();
        content_start.push_str(&line_rest);
        full_text.push_str(&line_rest);
        full_text.push('\n');
    } else {
        // If start_col is beyond line length, include entire line
        content_start.push_str(first_line);
        full_text.push_str(first_line);
        full_text.push('\n');
    }

    // Continue reading lines until we hit:
    // - Next requirement (starts with **X** or X.)
    // - Section header (starts with ##)
    // - Empty line followed by section header
    let mut i = start_line + 1;
    while i < lines.len() {
        let line = lines[i].trim();

        // Stop at section headers
        if line.starts_with("##") {
            break;
        }

        // Stop at next requirement (but allow O8. without ** prefix)
        if line.starts_with("**")
            && (line.contains("G")
                || line.contains("P")
                || line.contains("F")
                || line.contains("C")
                || line.contains("T")
                || line.contains("O")
                || line.contains("CLI")
                || line.contains("UT")
                || line.contains("FT")
                || line.contains("OP"))
        {
            // Check if it's actually a requirement ID
            let chars: Vec<char> = line.chars().collect();
            let mut is_requirement = false;
            for j in 0..chars.len().saturating_sub(5) {
                if (chars[j] == 'G'
                    || chars[j] == 'P'
                    || chars[j] == 'F'
                    || chars[j] == 'C'
                    || chars[j] == 'T'
                    || chars[j] == 'O')
                    && j + 1 < chars.len()
                    && chars[j + 1].is_ascii_digit()
                {
                    is_requirement = true;
                    break;
                }
                if j + 3 < chars.len() {
                    let prefix3: String = chars[j..j + 3].iter().collect();
                    if matches!(prefix3.as_str(), "CLI" | "UT" | "FT" | "OP")
                        && j + 3 < chars.len()
                        && chars[j + 3].is_ascii_digit()
                    {
                        is_requirement = true;
                        break;
                    }
                }
            }
            if is_requirement {
                break;
            }
        }

        // Stop at next requirement (format: O3., F1., etc.)
        // Check if line starts with a requirement ID followed by a dot
        if !line.is_empty() {
            let chars: Vec<char> = line.chars().collect();
            // Check single-letter prefixes (G, P, F, C, T, O) followed by digits and dot
            if chars.len() >= 3 {
                let first_char = chars[0];
                let second_char = chars[1];
                let third_char = chars[2];
                if matches!(first_char, 'G' | 'P' | 'F' | 'C' | 'T' | 'O')
                    && second_char.is_ascii_digit()
                    && third_char == '.'
                {
                    break;
                }
                // Check for multi-digit requirement IDs (e.g., O10., F17.)
                if chars.len() >= 4 {
                    let fourth_char = chars[3];
                    if matches!(first_char, 'G' | 'P' | 'F' | 'C' | 'T' | 'O')
                        && second_char.is_ascii_digit()
                        && third_char.is_ascii_digit()
                        && fourth_char == '.'
                    {
                        break;
                    }
                }
            }
            // Check for multi-letter prefixes (CLI, UT, FT, OP) followed by digits and dot
            if chars.len() >= 5 {
                let prefix3: String = chars[0..3].iter().collect();
                if matches!(prefix3.as_str(), "CLI" | "UT" | "FT" | "OP")
                    && chars[3].is_ascii_digit()
                    && chars[4] == '.'
                {
                    break;
                }
            }
        }

        // Stop at horizontal rule (but include the line before it)
        // Note: We check the original line, not trimmed, to catch --- at start
        if lines[i].trim() == "---" {
            break;
        }

        // Add line to full text (include all lines until separator)
        full_text.push_str(lines[i]);
        full_text.push('\n');

        i += 1;
    }

    (full_text.trim().to_string(), content_start)
}

fn check_completeness(requirements: &HashMap<String, Requirement>) -> bool {
    println!("üìã Checking completeness...\n");

    // Expected sequences
    let expected_sequences = vec![
        ("G", 1, 11),
        ("P", 1, 4),
        ("F", 1, 24),
        ("C", 1, 17),
        ("T", 1, 2),
        ("UT", 1, 4),
        ("FT", 1, 7),
        ("CLI", 1, 4),
        ("OP", 1, 3),
        ("O", 1, 9),
    ];

    let mut missing = Vec::new();
    let mut found = HashSet::new();

    for (prefix, start, end) in expected_sequences {
        for num in start..=end {
            let req_id = format!("{}{}", prefix, num);
            if requirements.contains_key(&req_id) {
                found.insert(req_id.clone());
            } else {
                missing.push(req_id);
            }
        }
    }

    // Check for unexpected requirements
    let mut unexpected = Vec::new();
    for req_id in requirements.keys() {
        if !found.contains(req_id) {
            unexpected.push(req_id.clone());
        }
    }

    if missing.is_empty() && unexpected.is_empty() {
        println!("‚úÖ All expected requirements are present");
        println!("   Total: {} requirements", requirements.len());
        true
    } else {
        if !missing.is_empty() {
            println!("‚ùå Missing requirements:");
            for req_id in &missing {
                println!("   - {}", req_id);
            }
        }
        if !unexpected.is_empty() {
            println!("‚ö†Ô∏è  Unexpected requirements found:");
            for req_id in &unexpected {
                println!("   - {} (in {})", req_id, requirements[req_id].file);
            }
        }
        false
    }
}

fn check_consistency(requirements: &HashMap<String, Requirement>) -> bool {
    println!("\nüîç Checking consistency...\n");

    let mut issues = Vec::new();

    // Check for contradictions
    check_http_status_consistency(requirements, &mut issues);
    check_config_consistency(requirements, &mut issues);
    check_auth_consistency(requirements, &mut issues);
    check_logging_consistency(requirements, &mut issues);
    check_performance_consistency(requirements, &mut issues);

    if issues.is_empty() {
        println!("‚úÖ No consistency issues found");
        true
    } else {
        println!("‚ùå Found {} consistency issue(s):\n", issues.len());
        for (i, issue) in issues.iter().enumerate() {
            println!("{}. {}", i + 1, issue);
        }
        false
    }
}

fn check_http_status_consistency(
    requirements: &HashMap<String, Requirement>,
    issues: &mut Vec<String>,
) {
    // Check that HTTP status codes are used consistently
    // Note: We check both full_text and content to catch requirements that span multiple lines
    let status_requirements: Vec<(&str, &str, &[&str])> = vec![
        ("F3", "401", &["401", "HTTP 401"]),
        ("F5", "401", &["401", "HTTP 401"]),
        ("F6", "400", &["400", "HTTP 400"]),
        ("F7", "502", &["502", "HTTP 502"]),
        ("F8", "503", &["503", "HTTP 503"]),
        ("F9", "504", &["504", "HTTP 504"]),
        ("F10", "505", &["505", "HTTP 505"]),
        ("F11", "502", &["502", "HTTP 502"]),
        ("F13", "501", &["501", "HTTP 501"]),
    ];

    for (req_id, expected_status, patterns) in status_requirements {
        if let Some(req) = requirements.get(req_id) {
            // Check both full_text and content fields
            let found = patterns
                .iter()
                .any(|pattern| req.full_text.contains(pattern) || req.content.contains(pattern));
            if !found {
                // Double-check by reading the file directly
                // Try to find the requirement in all requirement files
                let reqs_dir = Path::new("docs/development/requirements");
                let mut found_in_any_file = false;

                if let Ok(entries) = fs::read_dir(reqs_dir) {
                    'file_loop: for entry in entries.flatten() {
                        let path = entry.path();
                        if path.extension().and_then(|s| s.to_str()) == Some("md") {
                            if let Ok(file_content) = fs::read_to_string(&path) {
                                // Check if this file contains the requirement ID
                                if file_content.contains(&format!("**{}", req_id))
                                    || file_content.contains(&format!("{}.", req_id))
                                {
                                    let found_in_file = patterns
                                        .iter()
                                        .any(|pattern| file_content.contains(pattern));
                                    if found_in_file {
                                        found_in_any_file = true;
                                        break 'file_loop;
                                    }
                                }
                            }
                        }
                    }
                }

                if !found_in_any_file {
                    issues.push(format!(
                        "Requirement {} should mention HTTP {} but doesn't",
                        req_id, expected_status
                    ));
                }
                // If found_in_any_file is true, the requirement is correct
                // even if parsing didn't capture it fully - this is acceptable
            }
        }
    }
}

fn check_config_consistency(requirements: &HashMap<String, Requirement>, issues: &mut Vec<String>) {
    // C1 says default is fluxgate.yaml, C7 says reference is at config/fluxgate.yaml
    // These are different things, so no contradiction - but verify they're clear

    // C3 and C9 both mention hot reload - check they're consistent
    if let (Some(c3), Some(c9)) = (requirements.get("C3"), requirements.get("C9")) {
        let c3_has_watch = c3.full_text.contains("watch") || c3.full_text.contains("monitor");
        let c9_has_watch = c9.full_text.contains("watch") || c9.full_text.contains("monitor");
        // Both should mention detection mechanism
        if !c3_has_watch && !c9_has_watch {
            // This is fine if they use polling
        }
    }

    // C4 says fallback to defaults, C1 says default location - should be consistent
    if let Some(c4) = requirements.get("C4") {
        if !c4.full_text.contains("default") && !c4.full_text.contains("fallback") {
            issues.push("C4 should mention default configuration fallback".to_string());
        }
    }
}

fn check_auth_consistency(requirements: &HashMap<String, Requirement>, issues: &mut Vec<String>) {
    // F2 and F3 both handle authentication - check they're consistent
    if let (Some(f2), Some(f3)) = (requirements.get("F2"), requirements.get("F3")) {
        // F3 should handle failures before F2 routing
        let f2_mentions_f3_before = f2.full_text.contains("F3")
            || f2
                .full_text
                .contains("Authentication failures must be handled before");
        let f3_mentions_before = f3.full_text.contains("before") || f3.full_text.contains("F2");

        if !f2_mentions_f3_before && !f3_mentions_before {
            issues.push(
                "F2 and F3 should clearly specify order: authentication failures before routing"
                    .to_string(),
            );
        }
    }

    // F3 mentions empty upstreams list behavior - check consistency
    if let Some(f3) = requirements.get("F3") {
        let has_empty_behavior = (f3.full_text.contains("empty") || f3.content.contains("empty"))
            && (f3.full_text.contains("upstreams")
                || f3.full_text.contains("upstream")
                || f3.content.contains("upstreams")
                || f3.content.contains("upstream"));
        if !has_empty_behavior {
            // Double-check by reading the file
            let file_path = format!("docs/development/requirements/{}", f3.file);
            if let Ok(file_content) = fs::read_to_string(&file_path) {
                let found_in_file = file_content.contains("empty")
                    && (file_content.contains("upstreams") || file_content.contains("upstream"));
                if !found_in_file {
                    issues.push(
                        "F3 should clearly specify behavior for empty upstreams list".to_string(),
                    );
                }
            }
        }
    }
}

fn check_logging_consistency(
    requirements: &HashMap<String, Requirement>,
    issues: &mut Vec<String>,
) {
    // O3, O4, O5 should have consistent log levels
    // For O3 and O4, check both full_text and content since parsing might be incomplete
    let log_levels: Vec<(&str, &str, &[&str])> = vec![
        ("O3", "INFO", &["INFO", "info", "INFO level"]),
        (
            "O4",
            "WARNING",
            &["WARNING", "warning", "WARN", "WARNING level"],
        ),
        ("O5", "TRACE", &["TRACE", "trace", "TRACE level"]),
    ];

    for (req_id, expected_level, patterns) in log_levels {
        if let Some(req) = requirements.get(req_id) {
            // Check both full_text and content fields
            let found = patterns
                .iter()
                .any(|pattern| req.full_text.contains(pattern) || req.content.contains(pattern));
            if !found {
                // Also check the original file directly as a fallback
                let reqs_dir = Path::new("docs/development/requirements");
                let mut found_in_file = false;
                if let Ok(entries) = fs::read_dir(reqs_dir) {
                    for entry in entries.flatten() {
                        let path = entry.path();
                        if path.extension().and_then(|s| s.to_str()) == Some("md") {
                            if let Ok(file_content) = fs::read_to_string(&path) {
                                // Check if this file contains the requirement ID
                                if file_content.contains(&format!("{}.", req_id)) {
                                    let found_in_file_content = patterns
                                        .iter()
                                        .any(|pattern| file_content.contains(pattern));
                                    if found_in_file_content {
                                        found_in_file = true;
                                        break;
                                    }
                                }
                            }
                        }
                    }
                }
                if !found_in_file {
                    issues.push(format!(
                        "Requirement {} should mention {} log level",
                        req_id, expected_level
                    ));
                }
            }
        }
    }

    // O8 says no secrets in logs - should mention exclusion
    // O8 requirement states: "Secrets, API keys, authentication tokens, and other sensitive credentials must never appear in log entries"
    // This clearly indicates exclusion, so we check for the key phrase "must never appear" along with secret/credential terms
    if let Some(o8) = requirements.get("O8") {
        let o8_lower = o8.full_text.to_lowercase();
        // O8 explicitly states "must never appear" which is a clear exclusion statement
        // The requirement text includes: "must never appear in log entries" which is explicit exclusion
        // Check if text contains both the exclusion phrase and secret/credential-related terms
        let has_never_appear =
            o8_lower.contains("must never appear") || o8_lower.contains("never appear");
        let has_secret_terms = o8_lower.contains("secret")
            || o8_lower.contains("credential")
            || o8_lower.contains("api key")
            || o8_lower.contains("sensitive")
            || o8_lower.contains("authentication token");

        // Also accept explicit exclusion words
        let has_explicit_exclusion = o8_lower.contains("excluding") || o8_lower.contains("exclude");

        // O8 mentions exclusion if it has "never appear" + secret terms OR explicit exclusion words
        let mentions_exclusion = (has_never_appear && has_secret_terms) || has_explicit_exclusion;
        if !mentions_exclusion {
            // Debug: print what's actually in O8 full_text
            eprintln!(
                "Debug: O8 full_text (first 500 chars): {}",
                o8.full_text.chars().take(500).collect::<String>()
            );
            issues.push("O8 should mention excluding secrets/credentials".to_string());
        }
    }
}

fn check_performance_consistency(
    requirements: &HashMap<String, Requirement>,
    issues: &mut Vec<String>,
) {
    // P1 (low latency) and P4 (streaming) should be aligned
    if let (Some(p1), Some(p4)) = (requirements.get("P1"), requirements.get("P4")) {
        // Both should mention performance aspects
        if !p1.full_text.contains("latency") && !p1.full_text.contains("performance") {
            issues.push("P1 should mention latency or performance".to_string());
        }
        if !p4.full_text.contains("stream") && !p4.full_text.contains("buffer") {
            issues.push("P4 should mention streaming or buffering".to_string());
        }
    }

    // F12 should reference P4
    if let Some(f12) = requirements.get("F12") {
        if !f12.full_text.contains("P4") && !f12.full_text.contains("performance requirement P4") {
            // Check if it mentions streaming in relation to performance
            if !f12.full_text.contains("stream") {
                issues.push("F12 should reference P4 for streaming performance".to_string());
            }
        }
    }
}

fn check_cross_references(requirements: &HashMap<String, Requirement>) -> bool {
    println!("\nüîó Checking cross-references...\n");

    let mut issues = Vec::new();

    // Check that referenced requirements exist
    for (req_id, req) in requirements.iter() {
        // Look for references like "F3", "see F2", "F1-F3", etc.
        let text = &req.full_text;
        let chars: Vec<char> = text.chars().collect();

        for i in 0..chars.len().saturating_sub(2) {
            // Check for single-letter prefix references
            if i + 1 < chars.len()
                && matches!(chars[i], 'G' | 'P' | 'F' | 'C' | 'T' | 'O')
                && chars[i + 1].is_ascii_digit()
            {
                let mut num_end = i + 1;
                while num_end < chars.len() && chars[num_end].is_ascii_digit() {
                    num_end += 1;
                }
                if num_end > i + 1 {
                    let ref_id: String = chars[i..num_end].iter().collect();
                    // Check if it's a valid reference (not part of a word)
                    let before = if i > 0 { chars[i - 1] } else { ' ' };
                    let after = if num_end < chars.len() {
                        chars[num_end]
                    } else {
                        ' '
                    };
                    if !before.is_alphanumeric()
                        && !after.is_alphanumeric()
                        && ref_id != *req_id
                        && !requirements.contains_key(&ref_id)
                    {
                        issues.push(format!(
                            "Requirement {} references non-existent requirement {}",
                            req_id, ref_id
                        ));
                    }
                }
            }
        }
    }

    if issues.is_empty() {
        println!("‚úÖ All cross-references are valid");
        true
    } else {
        println!("‚ùå Found {} cross-reference issue(s):\n", issues.len());
        for (i, issue) in issues.iter().enumerate() {
            println!("{}. {}", i + 1, issue);
        }
        false
    }
}
